---
title: "Pokemon Machine Learning"
author: "Aankur Bhatia"
output: html_notebook
---

Load the required packages

```{r}
all_packages=list("dplyr","caret","ggplot2","mlr","DT")

lapply(all_packages,require,character.only=TRUE)
library(mlr)
```

load the Pokemon dataset next

```{r}
pokemon=read.csv("pokemon_alopez247.csv",stringsAsFactors = TRUE)
```

Summarize data using summarize columns command

```{r}
str(pokemon)
summarizeColumns(pokemon)
summary(pokemon)
head(pokemon)
table(pokemon$hasMegaEvolution)
table(pokemon$isLegendary)

```



Remove columns that will not be used in machine learning

1. Number
2. Name 

```{r}
pokemon$Number=NULL
pokemon$Name=NULL
```

Removing variable that have large missing values - Type_2, Egg_Group_2
```{r}
pokemon$Type_2=NULL
pokemon$Egg_Group_2=NULL
```

Keep only records with hasGender =TRUE

```{r}
library(dplyr)
table(pokemon$hasGender)
pokemon=pokemon %>%
  filter(hasGender=="True")
```

looking at the summary once again

```{r}
summarizeColumns(pokemon)
summary(pokemon)
#remove has Gender
pokemon$hasGender=NULL
str(pokemon)
#find levels of hasMegaEvolution
table(pokemon$hasMegaEvolution)
#mostly false
```

We'll do a multiclassification with Egg_Group1 as the response variable (15 levels) using MLR Package


We will remove variables that have high correlation- multicollinearity. We find predictor correlation

```{r}
#find numeric columns
numcols=pokemon %>% 
  select_if(is.numeric)
varcorr=cor(numcols)
library(corrplot)

corrplot(varcorr,order = "hclust")

highcorr=findCorrelation(varcorr,cutoff = 0.65)
#It shows the first variable 'Total' has high correlation with other variables
pokemon$Total=NULL
```

Let us now preprocess data using center, scale transformations (standardize)

```{r}
pokemon=normalizeFeatures(pokemon,target = "Egg_Group_1",method = "standardize")
summary(pokemon)
```

First let's load the MLR package, and perform data splitting

```{r}
library(mlr)

trainsample=sample(nrow(pokemon),0.6*nrow(pokemon),replace = FALSE)
testsample=setdiff(1:nrow(pokemon),trainsample)
```

Now, we create the classification task for the pokemon dataset

```{r}
#remove the empty factor levels from Egg_Group_1
table(pokemon$Egg_Group_1)
pokemon$Egg_Group_1=factor(pokemon$Egg_Group_1)
pokemontraintask=makeClassifTask(data = pokemon[trainsample,],target = "Egg_Group_1")
pokemontraintask

```


Find learners that can perform multiclass classification. Then create a benchmarking list of at-least 4-5 such learners

```{r}
poklearnersall=listLearners(pokemontraintask,warn.missing.packages = FALSE)[c("class","package")]
#we choose rpart, randomForest, Neural Network, ksvm, C50, gbm for creating the benchmark experiment
pokemonbenchlearners=list(makeLearner("classif.rpart",predict.type = "prob",fix.factors.prediction = TRUE),
                          makeLearner("classif.randomForest",predict.type = "prob",fix.factors.prediction = TRUE),
                          makeLearner("classif.nnet",predict.type = "prob",fix.factors.prediction = TRUE),
                          makeLearner("classif.boosting",predict.type = "prob",fix.factors.prediction = TRUE),
                          makeLearner("classif.C50",predict.type = "prob",fix.factors.prediction = TRUE),
                          makeLearner("classif.gbm",predict.type = "prob",fix.factors.prediction = TRUE))
pokemonbenchlearners
```

Now, we create a benchmark strategy for the resampling. We'll choose cross validation with 2 iterations. We will keep stratify =FALSE since each sample may not have all the classes

```{r}
#Resampling Strategy
pokemonresamplingbench=makeResampleDesc(method = "CV",iters=2)
pokemonresamplingbench
```

Next, we define the performance measures to be estimated for this experiment. Let's take a look at all performance measures and then select appropriate ones for this benchmarking experiment

```{r}
listMeasures(pokemontraintask)
pokemonbenchmeasures=list(kappa,multiclass.brier,acc,ber,logloss,timeboth)
pokemonbenchmeasures
```

Finally, run the benchmark experiment

```{r}
pokemonbench=benchmark(learners = pokemonbenchlearners,tasks = pokemontraintask,resamplings = pokemonresamplingbench,measures = pokemonbenchmeasures)
pokemonbench
#just perform resample using boosting  algorithm (which gave the best results)
boost.learner=makeLearner("classif.boosting",predict.type = "prob",fix.factors.prediction = TRUE)
boost.resamp=makeResampleDesc("CV",iters=5)

boost.resampleexpt=resample(learner = boost.learner,task = pokemontraintask,resampling = boost.resamp,measures = pokemonbenchmeasures,extract = function(x) x$learner.model$variable.importance)
boost.resampleexpt$aggr
boost.resampleexpt$extract
boost.resampleexpt$pred
boost.resampleexpt$measures.test

```

Let's do hyper parameter tuning to achieve better performance. Let's use the classif.booting for the classification. Let's first get all the parameters for classif.boosting algorithm

```{r}
getParamSet("classif.boosting")
```

Now, let's set the hyperparameters using the search parameters

```{r}
boost.search=makeParamSet(
  makeIntegerParam("mfinal",lower = 75,upper = 150),
  makeNumericParam("cp",lower=0.005,upper=0.05),
  makeIntegerParam("maxdepth",lower=10,upper=30)
)

```

Now, find the parameter search algorithm

```{r}
boost.algorithm=makeTuneControlRandom(maxit = 30)
```


Finally, perform the tuning 


```{r}

#run the hyperparameter tuning process
boost.hypertune=tuneParams(learner = boost.learner,task = pokemontraintask,resampling = boost.resamp,measures = pokemonbenchmeasures,par.set = boost.search,control = boost.algorithm)
boost.hypertune
boost.hypertune$opt.path
names(boost.hypertune)
boost.hypertune$y
#perform the visualization for the best hyper parameters
optimum.grid=as.data.frame(boost.hypertune$opt.path)
optimum.grid
g=ggplot(optimum.grid,aes(x = mfinal,y= cp,fill=acc.test.mean,label=round(acc.test.mean,3)))
g+geom_tile()+geom_text(color="white")
```

Overall accuracy of 69.12% which is actually lower than the mean accuracy obtained during resampling experiment using the default hyperparameters

So, we stick to the default learner (with default hyperparameters) and perform the model training

```{r}
boost.train=mlr::train(learner = boost.learner,task = pokemontraintask)
boost.train
```

Let's predict using the training model built

```{r}

boost.predict=predict(boost.train,newdata = pokemon,subset = testsample)
boost.predict

confusionMatrix(boost.predict$data$truth,boost.predict$data$response)
```

Overall accuracy of 65.5%

Let's see other measures of performance for this task

```{r}
listMeasures(pokemontraintask)
performance(pred = boost.predict,measures = list(acc,mmce,kappa),task = pokemontraintask,model = boost.train)
```
accuracy of 65.5% and mean classification error of 34.49%

Instead let's take the selected hyperparameters and train and predict using those to see if we can achieve higher accuracy

```{r}
#creating a learner with the optimal hyperparameters
final.learner=setHyperPars(makeLearner("classif.boosting",par.vals = boost.hypertune$x))
final.learner
#we again train the machine using the final learner and predict on the test set once again
final.train=mlr::train(learner = final.learner,task = pokemontraintask)
final.train
final.predict=predict(object = final.train,newdata = pokemon,subset = testsample)
confusionMatrix(final.predict$data$truth,final.predict$data$response)
```

As expected, the accuracy has infact fallen by using the selected hyperparameters. Some other performance measures

```{r}
calculateConfusionMatrix(final.predict,relative = TRUE,sums = TRUE)
performance(pred = final.predict,measures = list(acc,mmce,kappa),task = pokemontraintask,model = final.train)
```




